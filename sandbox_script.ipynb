{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8f4916b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import argparse\n",
    "\n",
    "import torchaudio\n",
    "import torch\n",
    "import re\n",
    "import json \n",
    "import librosa\n",
    "from datasets import load_from_disk, load_dataset, load_metric\n",
    "\n",
    "from transformers import (\n",
    "    Wav2Vec2Processor, \n",
    "    Wav2Vec2CTCTokenizer,\n",
    "    Wav2Vec2FeatureExtractor,\n",
    "    Wav2Vec2ForCTC,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    HfArgumentParser,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "\n",
    "from datasets import DatasetDict, load_metric, load_from_disk\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Any, Dict, List, Optional, Union\n",
    "import datasets\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741a872b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####\n",
    "# Common Functions\n",
    "#####\n",
    "CHARS_TO_IGNORE = [\",\", \"?\", \"¿\", \".\", \"!\", \"¡\", \";\", \"；\", \":\", '\"\"', \"%\", '\"', \"�\", \"ʿ\", \"·\", \"჻\", \"~\", \"՞\",\n",
    "                   \"؟\", \"،\", \"।\", \"॥\", \"«\", \"»\", \"„\", \"“\", \"”\", \"「\", \"」\", \"‘\", \"’\", \"《\", \"》\", \"(\", \")\", \"[\", \"]\",\n",
    "                   \"{\", \"}\", \"=\", \"`\", \"_\", \"+\", \"<\", \">\", \"…\", \"–\", \"°\", \"´\", \"ʾ\", \"‹\", \"›\", \"©\", \"®\", \"—\", \"→\", \"。\",\n",
    "                   \"、\", \"﹂\", \"﹁\", \"‧\", \"～\", \"﹏\", \"，\", \"｛\", \"｝\", \"（\", \"）\", \"［\", \"］\", \"【\", \"】\", \"‥\", \"〽\",\n",
    "                   \"『\", \"』\", \"〝\", \"〟\", \"⟨\", \"⟩\", \"〜\", \"：\", \"！\", \"？\", \"♪\", \"؛\", \"/\", \"\\\\\", \"º\", \"−\", \"^\", \"ʻ\", \"ˆ\"]\n",
    "\n",
    "def remove_special_characters(batch):\n",
    "    batch[\"sentence\"] = re.sub(chars_to_ignore_regex, '', batch[\"sentence\"]).lower() + \" \"\n",
    "    return batch\n",
    "\n",
    "def extract_all_chars(batch):\n",
    "    all_text = \" \".join(batch[\"sentence\"])\n",
    "    vocab = list(set(all_text))\n",
    "    return {\"vocab\": [vocab], \"all_text\": [all_text]}\n",
    "\n",
    "#####\n",
    "# Data Loading Function\n",
    "#####\n",
    "def speech_file_to_array_fn(batch):\n",
    "    speech_array, sampling_rate = torchaudio.load(batch[\"audio_path\"])\n",
    "    batch[\"speech_sample\"] = speech_array[0].numpy()\n",
    "    batch[\"sampling_rate\"] = sampling_rate\n",
    "    return batch\n",
    "\n",
    "def load_dataset(manifest_file, num_proc):\n",
    "    batches = {\"path\": [], \"text\": [], \"target_sample_rate\": []}\n",
    "    base_path = '/'.join(manifest_file.split('/')[:-1])\n",
    "    \n",
    "    manifest_df = pd.read_csv(manifest_file)\n",
    "    manifest_df = manifest_df.rename({'text': 'target_text'}, axis=1)\n",
    "    manifest_df['audio_path'] = manifest_df['audio_path'].apply(lambda path: f'{base_path}/{path}')\n",
    "        \n",
    "    batches = Dataset.from_pandas(manifest_df)\n",
    "    batches = batches.map(speech_file_to_array_fn, num_proc=num_proc)\n",
    "    return batches\n",
    "\n",
    "#####\n",
    "# Data Collator\n",
    "#####\n",
    "@dataclass\n",
    "class DataCollatorCTCWithPadding:\n",
    "    \"\"\"\n",
    "    Data collator that will dynamically pad the inputs received.\n",
    "    Args:\n",
    "        processor (:class:`~transformers.Wav2Vec2Processor`)\n",
    "            The processor used for proccessing the data.\n",
    "        padding (:obj:`bool`, :obj:`str` or :class:`~transformers.tokenization_utils_base.PaddingStrategy`, `optional`, defaults to :obj:`True`):\n",
    "            Select a strategy to pad the returned sequences (according to the model's padding side and padding index)\n",
    "            among:\n",
    "            * :obj:`True` or :obj:`'longest'`: Pad to the longest sequence in the batch (or no padding if only a single\n",
    "              sequence if provided).\n",
    "            * :obj:`'max_length'`: Pad to a maximum length specified with the argument :obj:`max_length` or to the\n",
    "              maximum acceptable input length for the model if that argument is not provided.\n",
    "            * :obj:`False` or :obj:`'do_not_pad'` (default): No padding (i.e., can output a batch with sequences of\n",
    "              different lengths).\n",
    "        max_length (:obj:`int`, `optional`):\n",
    "            Maximum length of the ``input_values`` of the returned list and optionally padding length (see above).\n",
    "        max_length_labels (:obj:`int`, `optional`):\n",
    "            Maximum length of the ``labels`` returned list and optionally padding length (see above).\n",
    "        pad_to_multiple_of (:obj:`int`, `optional`):\n",
    "            If set will pad the sequence to a multiple of the provided value.\n",
    "            This is especially useful to enable the use of Tensor Cores on NVIDIA hardware with compute capability >=\n",
    "            7.5 (Volta).\n",
    "    \"\"\"\n",
    "\n",
    "    processor: Wav2Vec2Processor\n",
    "    padding: Union[bool, str] = True\n",
    "    max_length: Optional[int] = None\n",
    "    max_length_labels: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "    pad_to_multiple_of_labels: Optional[int] = None\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # split inputs and labels since they have to be of different lenghts and need\n",
    "        # different padding methods\n",
    "        input_features = [{\"input_values\": feature[\"input_values\"]} for feature in features]\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "\n",
    "        batch = self.processor.pad(\n",
    "            input_features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        with self.processor.as_target_processor():\n",
    "            labels_batch = self.processor.pad(\n",
    "                label_features,\n",
    "                padding=self.padding,\n",
    "                max_length=self.max_length_labels,\n",
    "                pad_to_multiple_of=self.pad_to_multiple_of_labels,\n",
    "                return_tensors=\"pt\",\n",
    "            )\n",
    "\n",
    "        # replace padding with -100 to ignore loss correctly\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch\n",
    "\n",
    "#####\n",
    "# Compute Metric Function\n",
    "#####\n",
    "wer_metric = load_metric(\"wer\")\n",
    "cer_metric = load_metric(\"cer\")\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    pred_logits = pred.predictions\n",
    "    pred_ids = np.argmax(pred_logits, axis=-1)\n",
    "    pred.label_ids[pred.label_ids == -100] = processor.tokenizer.pad_token_id\n",
    "\n",
    "    pred_str = processor.batch_decode(pred_ids)\n",
    "\n",
    "    # we do not want to group tokens when computing the metrics\n",
    "    label_str = processor.batch_decode(pred.label_ids, group_tokens=False)\n",
    "    wer = wer_metric.compute(predictions=pred_str, references=label_str)\n",
    "    cer = cer_metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    return {\"cer\": cer}\n",
    "\n",
    "#####\n",
    "# Main Functions\n",
    "#####\n",
    "def run(model_args, data_args, training_args):\n",
    "    ###\n",
    "    # Prepare Dataset\n",
    "    ###\n",
    "    raw_datasets = DatasetDict()\n",
    "    raw_datasets[\"train\"] = load_dataset(data_args.train_manifest_path, data_args.num_proc)\n",
    "    raw_datasets[\"valid\"] = load_dataset(data_args.valid_manifest_path, data_args.num_proc)\n",
    "    raw_datasets[\"test\"] = load_dataset(data_args.test_manifest_path, data_args.num_proc)\n",
    "\n",
    "    ###\n",
    "    # Prepare Processor & Model    \n",
    "    ###\n",
    "    processor = Wav2Vec2Processor.from_pretrained(model_args.model_name_or_path)\n",
    "    model = Wav2Vec2ForCTC.from_pretrained(model_args.model_name_or_path)\n",
    "    model.cuda()\n",
    "    \n",
    "    ###\n",
    "    # Preprocessing datasets\n",
    "    ###\n",
    "    # Remove ignorable characters\n",
    "    chars_to_ignore_regex = f\"[{re.escape(''.join(CHARS_TO_IGNORE))}]\"\n",
    "    def remove_special_characters(batch):\n",
    "        if chars_to_ignore_regex is not None:\n",
    "            batch[\"target_text\"] = re.sub(chars_to_ignore_regex, \"\", batch[data_args.text_column_name]).lower() + \" \"\n",
    "        else:\n",
    "            batch[\"target_text\"] = batch[data_args.text_column_name].lower() + \" \"\n",
    "        return batch\n",
    "\n",
    "    with training_args.main_process_first(desc=\"dataset map special characters removal\"):\n",
    "        raw_datasets = raw_datasets.map(\n",
    "            remove_special_characters,\n",
    "            remove_columns=[data_args.text_column_name],\n",
    "            desc=\"remove special characters from datasets\",\n",
    "        )\n",
    "        \n",
    "    # Preprocess audio sample and label text\n",
    "    def prepare_dataset(batch):\n",
    "        # Preprocess audio\n",
    "        batch[\"input_values\"] = processor(batch[\"speech_sample\"]).input_values[0]\n",
    "\n",
    "        # Preprocess text\n",
    "        with processor.as_target_processor():\n",
    "            batch[\"labels\"] = processor(batch[\"target_text\"]).input_ids\n",
    "            \n",
    "        return batch\n",
    "\n",
    "    with training_args.main_process_first(desc=\"dataset map preprocessing\"):\n",
    "        vectorized_datasets = raw_datasets.map(\n",
    "            prepare_dataset,\n",
    "            remove_columns=raw_datasets[\"train\"].column_names,\n",
    "            num_proc=data_args.preprocessing_num_workers,\n",
    "            desc=\"preprocess datasets\",\n",
    "        )\n",
    "\n",
    "    if data_args.preprocessing_only:\n",
    "        logger.info(f\"Data preprocessing finished. Files cached at {vectorized_datasets.cache_files}\")\n",
    "        return\n",
    "    \n",
    "    ###\n",
    "    # Prepare Data Collator and Trainer\n",
    "    ###\n",
    "    # Instantiate custom data collator\n",
    "    data_collator = DataCollatorCTCWithPadding(processor=processor)\n",
    "\n",
    "    # Initialize Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        data_collator=data_collator,\n",
    "        args=training_args,\n",
    "        compute_metrics=compute_metrics,\n",
    "        train_dataset=vectorized_datasets[\"train\"] if training_args.do_train else None,\n",
    "        eval_dataset=vectorized_datasets[\"valid\"] if training_args.do_eval else None,\n",
    "        tokenizer=processor.feature_extractor,\n",
    "    )\n",
    "\n",
    "    ###\n",
    "    # Training Phase\n",
    "    ###\n",
    "    if training_args.do_train:\n",
    "        # use last checkpoint if exist\n",
    "        if last_checkpoint is not None:\n",
    "            checkpoint = last_checkpoint\n",
    "        elif os.path.isdir(model_args.model_name_or_path):\n",
    "            checkpoint = model_args.model_name_or_path\n",
    "        else:\n",
    "            checkpoint = None\n",
    "\n",
    "        # Save the feature_extractor and the tokenizer\n",
    "        if is_main_process(training_args.local_rank):\n",
    "            processor.save_pretrained(training_args.output_dir)\n",
    "\n",
    "        train_result = trainer.train(resume_from_checkpoint=checkpoint)\n",
    "        trainer.save_model()\n",
    "\n",
    "        metrics = train_result.metrics\n",
    "        max_train_samples = (\n",
    "            data_args.max_train_samples\n",
    "            if data_args.max_train_samples is not None\n",
    "            else len(vectorized_datasets[\"train\"])\n",
    "        )\n",
    "        metrics[\"train_samples\"] = min(max_train_samples, len(vectorized_datasets[\"train\"]))\n",
    "\n",
    "        trainer.log_metrics(\"train\", metrics)\n",
    "        trainer.save_metrics(\"train\", metrics)\n",
    "        trainer.save_state()\n",
    "\n",
    "    ###\n",
    "    # Evaluation Phase\n",
    "    ###\n",
    "    results = {}\n",
    "    if training_args.do_eval:\n",
    "        logger.info(\"*** Evaluate ***\")\n",
    "        metrics = trainer.evaluate(eval_dataset=vectorized_datasets[\"test\"])\n",
    "        metrics[\"eval_samples\"] = len(vectorized_datasets[\"test\"])\n",
    "\n",
    "        trainer.log_metrics(\"eval\", metrics)\n",
    "        trainer.save_metrics(\"eval\", metrics)\n",
    "\n",
    "    # Write model card and (optionally) push to hub\n",
    "    kwargs = {\n",
    "        \"finetuned_from\": model_args.model_name_or_path,\n",
    "        \"tasks\": \"speech-recognition\",\n",
    "        \"tags\": [\"automatic-speech-recognition\", \"ASCEND\"],\n",
    "        \"dataset_args\": f\"Config: na,\n",
    "        \"dataset\": f\"ASCEND\",\n",
    "        \"language\": 'zh-en'\n",
    "    }\n",
    "\n",
    "    if training_args.push_to_hub:\n",
    "        trainer.push_to_hub(**kwargs)\n",
    "    else:\n",
    "        trainer.create_model_card(**kwargs)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def main():\n",
    "    ###\n",
    "    # Parsing & Initialization\n",
    "    ###\n",
    "    # Parse argument\n",
    "    parser = HfArgumentParser((ModelArguments, DataTrainingArguments, TrainingArguments))\n",
    "    if len(sys.argv) == 2 and sys.argv[1].endswith(\".json\"):\n",
    "        model_args, data_args, training_args = parser.parse_json_file(json_file=os.path.abspath(sys.argv[1]))\n",
    "    else:\n",
    "        model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n",
    "\n",
    "    # Set random seed\n",
    "    set_seed(training_args.seed)\n",
    "    \n",
    "    # Detect last checkpoint\n",
    "    last_checkpoint = None\n",
    "    if os.path.isdir(training_args.output_dir) and training_args.do_train and not training_args.overwrite_output_dir:\n",
    "        last_checkpoint = get_last_checkpoint(training_args.output_dir)\n",
    "        if last_checkpoint is None and len(os.listdir(training_args.output_dir)) > 0:\n",
    "            raise ValueError(\n",
    "                f\"Output directory ({training_args.output_dir}) already exists and is not empty. \"\n",
    "                \"Use --overwrite_output_dir to overcome.\"\n",
    "            )\n",
    "        elif last_checkpoint is not None:\n",
    "            logger.info(\n",
    "                f\"Checkpoint detected, resuming training at {last_checkpoint}. To avoid this behavior, change \"\n",
    "                \"the `--output_dir` or add `--overwrite_output_dir` to train from scratch.\"\n",
    "            )\n",
    "\n",
    "    ###\n",
    "    # Prepare logger\n",
    "    ###\n",
    "    # Init logging\n",
    "    logging.basicConfig(\n",
    "        format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
    "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "        handlers=[logging.StreamHandler(sys.stdout)],\n",
    "    )\n",
    "    logger.setLevel(logging.INFO if is_main_process(training_args.local_rank) else logging.WARN)\n",
    "\n",
    "    # Log on each process the small summary:\n",
    "    logger.warning(\n",
    "        f\"Process rank: {training_args.local_rank}, device: {training_args.device}, n_gpu: {training_args.n_gpu}\"\n",
    "        f\"distributed training: {bool(training_args.local_rank != -1)}, 16-bits training: {training_args.fp16}\"\n",
    "    )\n",
    "    # Set the verbosity to info of the Transformers logger (on main process only):\n",
    "    if is_main_process(training_args.local_rank):\n",
    "        transformers.utils.logging.set_verbosity_info()\n",
    "    logger.info(\"Training/evaluation parameters %s\", training_args)\n",
    "    \n",
    "    ###\n",
    "    # RUN RUN RUN!!!\n",
    "    ###\n",
    "    run(model_args, data_args, training_args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_ascend",
   "language": "python",
   "name": "env_ascend"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
